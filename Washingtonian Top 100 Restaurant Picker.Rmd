---
title: "Washingtonian Top 100 Restaurant Picker"
author: "Kate Lamoreaux"
date: "2023-10-28"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Libraries

#Feedback from Brian: How do we optimize restaurant choices? Building an interactive tool. MAke sure you have a clear goal in mind. RQ = can be goal we have in mind.

Ideas: could link `$$$$` ratings/star ratings/mapdata/website from google, star ratings from yelp (use yelp api; scraping is illegal).

```{r}
library(xml2)
library(rvest)
library(tidyverse)
library(tidytext)
library(jsonlite)
library(robotstxt)
library(RSocrata)
library(googleway)
library(httr)
library(readxl)
```


## 1. Washingtonian Web Scraping

```{r}
# see whether I can scrape
paths_allowed("https://www.washingtonian.com/2023/01/25/the-100-very-best-restaurants-in-washington-dc/")
```

Since this is true, I can scrape!

```{r}
# Reading in the html page as R object url
url <- read_html("https://www.washingtonian.com/2023/01/25/the-100-very-best-restaurants-in-washington-dc/")
```

```{r}
# Extracting the nodes from object url (using the `rvest` package) 
nds <- html_elements(url, xpath = '//*[contains(concat( " ", @class, " " ), concat( " ", "sm-tw-py-0", " " ))]')

str(nds)
```

```{r}
names <- html_text(nds)
head(names)
```

```{r}
#convert to a tibble
tophundred <- as_tibble(names)
head(tophundred)
```
```{r}
tophundred$value[1]
```

```{r}
# Remove "\n"

library(stringr)
tophundred$value <- gsub("[\n]+", "sepcol", tophundred$value)
tophundred$value[1]
```


```{r}
# Remove "sepcolRead Our ReviewsepcolVisit Website sepcol"
tophundred$value <- gsub("sepcolRead Our ReviewsepcolVisit Website sepcol", "", tophundred$value)
head(tophundred)
```

```{r}
#Using separate to clean and label columns
tophundred_clean <- tophundred %>%
  separate(value,c("blank","ranking","name", "ranking2", "name2", "genre", "address", "phone number"), 'sepcol') 
head(tophundred_clean)
```


```{r}
tophundred_final <- tophundred_clean %>%
  select(-c("blank", "ranking2", "name2"))
head(tophundred_final)
```

```{r}
# exporting the data
install.packages("openxlsx")
library(openxlsx)
exportlist <- write.xlsx(tophundred_final, "/Users/sungjoocho/Desktop/UMD/Fall2023/SURV727/Group_assignment/cho-lamoreaux-a1/wasingtonian_top100.xlsx")
```


## Data
```{r}
# Data from Washingtonion
washingtonion <- read_excel("/Users/sungjoocho/Desktop/UMD/Fall2023/SURV727/FinalProject/washingtonian-restaurants/wasingtonian_top100.xlsx")
washingtonion$ranking <- 1:100

# create key_name variable for merging
washingtonion$key_name <- gsub("[^A-Za-z0-9]", "", washingtonion$name)
head(washingtonion)
```

```{r}
# Data from Yelp
yelp <- read.csv("/Users/sungjoocho/Desktop/UMD/Fall2023/SURV727/FinalProject/output.csv")

# creating key_name variable for merging
yelp$key_name <- gsub("&", "and", yelp$name) # change & to "and"
yelp$key_name <- gsub("[^A-Za-z0-9]", "", yelp$key_name)
head(yelp)

# merge yelp data to washingtonion
washington_yelp <- washingtonion %>% left_join(yelp, by = "key_name")
head(washington_yelp)
```




