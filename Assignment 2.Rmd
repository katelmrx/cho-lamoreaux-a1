---
title: "Assignment 2"
author: "Sungjoo Cho, Catherine (Kate) Lamoreaux"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Packages

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(gtrendsR)
library(censusapi)
library(gtrendsR)
library(magrittr)

if (!require(tidyverse)) install.packages("tidyverse")
library(tidyverse)
library(magrittr)

library(censusapi)
library(ggplot2)
```

## Pulling from APIs

```{r}
# pulling from APIs
res <- gtrends(c("crime", "loans"),
               geo = "US-IL",
               time = "2020-01-01 2020-12-31",
               low_search_volume = TRUE)
head(res)
plot(res)

# transforming the `data.frame` into a `tibble`
str(res)
res_time <- as_tibble(res$interest_over_time)

glimpse(res_time)
head(table(res_time$date))
table(res_time$keyword)
table(res_time$geo)
```

### Answer the following questions for the keywords "crime" and "loans".

-   Find the mean, median and variance of the search hits for the keywords.

```{r}
# mean, median and variance of the search hits for the keywords
stat_keywords <- res_time %>%
  group_by(keyword) %>%
  summarize(mean = mean(hits),
            median = median(hits),
            variance = var(hits))

stat_keywords
knitr::kable(stat_keywords, caption = "Statistics of the search hits for the keywords")
```

-   Which cities (locations) have the highest search frequency for loans? Note that there might be multiple rows for each city if there were hits for both "crime" and "loans" in that city. It might be easier to answer this question if we had the search hits info for both search terms in two separate variables. That is, each row would represent a unique city.

Union has the highest search frequency for loans.

```{r}
# using pivot_wider
res_city <- res$interest_by_city %>%
  pivot_wider(names_from = keyword,
              values_from = hits)

# changing NA values to 0 for loans and crime
res_city['loans'][is.na(res_city['loans'])] <- 0
res_city['crime'][is.na(res_city['crime'])] <- 0

# sorting
res_city <- res_city[order(-res_city$loans), ]
head(res_city)
```

-   Is there a relationship between the search intensities between the two keywords we used?

The correlation between the search intensities of the two keywords is -0.1313. From the plot below shows the number of search hits (crime and loans) changes over time.

```{r}
# correlation
cor(res_city$crime, res_city$loans)

# plot of the number of search hits changes over time
plot(res)
```

### Repeat the above for keywords related to covid. Make sure you use multiple keywords like we did above. Try several different combinations and think carefully about words that might make sense within this context.

-   We tried several different combinations of keywords, including "trump", "death", "mask", and "virus." We found that "death" and "mask" were not searched nearly as frequently as "covid." "Virus" peaked early, during the onset of the U.S. lockdowns, but rapidly decreased, stabilizing around June 2020. In contrast, searches for "trump" remained high throughout 2020.

```{r}
#Commenting out code above to see if multiple keywords break the code.
res_covid <- gtrends(c("covid", "trump"),
               geo = "US-IL", 
               time = "2020-01-01 2021-12-31", 
               low_search_volume = TRUE)
head(res_covid)
plot(res_covid)
str(res_covid)

# transforming the `data.frame` into a `tibble`
res_covid_time <- as_tibble(res_covid$interest_over_time)
head(res_covid_time)

# changing '<1' values to 0 for hits values
res_covid_time$hits <- ifelse(res_covid_time$hits == '<1', 0, res_covid_time$hits)    
res_covid_time$hits <- as.integer(res_covid_time$hits)
str(res_covid_time)

glimpse(res_covid_time)
head(table(res_covid_time$date))
table(res_covid_time$keyword)
table(res_covid_time$geo)
```

Answer the following questions for the keywords "covid" and "trump".

-   Find the mean, median and variance of the search hits for the keywords.

```{r}
# mean, median and variance of the search hits for the keywords
stat_covid_keywords <- res_covid_time %>%
  group_by(keyword) %>%
  summarize(mean = mean(hits),
            median = median(hits),
            variance = var(hits))

knitr::kable(stat_covid_keywords, caption = "Statistics of the search hits for the keywords")
```

-   Which cities (locations) have the highest search frequency for `covid`? (Note that there might be multiple rows for each city if there were hits for keywords in that city. It might be easier to answer this question if we had the search hits info for both search terms in two separate variables. That is, each row would represent a unique city.

    -   Oak Lawn (100), Northbrook (99), and Wheaton (93) have the highest searches for `covid`.

```{r}
res_covid_city<- as_tibble(res_covid$interest_by_city)

res_covid_city['hits'][is.na(res_covid_city['hits'])] <- 0

res_covid_city[res_covid_city$location == "Windsor" & res_covid_city$hits ==63, "location"] <- "New Windsor"

# using pivot_wider
res_covid_city<- res_covid_city %>%
 pivot_wider(names_from = keyword,
            values_from = hits,
            values_fill = 0)

# changing NA values to 0 for loans
#res_covid_city['covid'][is.na(res_covid_city['covid'])] <- 0
#res_covid_city['trump'][is.na(res_covid_city['trump'])] <- 0

# sorting
res_covid_city <- res_covid_city[order(-res_covid_city$covid), ]
head(res_covid_city)
```

-   Is there a relationship between the search intensities between the two keywords we used?

```{r}
# correlation
cor(res_covid_city$covid, res_covid_city$trump)

# plot of the number of search hits changes over time
plot(res_covid)
qplot(res_covid_city$covid, res_covid_city$trump)
```

## Google Trends + ACS

Now lets add another data set. The `censusapi` package provides a nice R interface for communicating with this API. However, before running queries we need an access key. This (easy) process can be completed here:

<https://api.census.gov/data/key_signup.html>

Once you have an access key, store this key in the `cs_key` object. We will use this object in all following API queries.

```{r}
#| eval: false
cs_key <- "839176755fb51cd99853fa546eac00eb08b203fa"
```

In the following, we request basic socio-demographic information (population, median age, median household income, income per capita) for cities and villages in the state of Illinois.

```{r}
#| eval: false

acs_il <- getCensus(name = "acs/acs5",
                    vintage = 2020, 
                    vars = c("NAME", 
                             "B01001_001E", 
                             "B06002_001E", 
                             "B19013_001E", 
                             "B19301_001E"), 
                    region = "place:*", 
                    regionin = "state:17",
                    key = cs_key)
head(acs_il)
```

Convert values that represent missings to NAs.

```{r}
#| eval: false

acs_il[acs_il == -666666666] <- NA
```

Now, it might be useful to rename the socio-demographic variables (`B01001_001E` etc.) in our data set and assign more meaningful names.

```{r}
#| eval: false
acs_il <-
  acs_il %>%
  rename(pop = 'B01001_001E', 
         age = 'B06002_001E', 
         hh_income = 'B19013_001E', 
         income = 'B19301_001E')
```

It seems like we could try to use this location information listed above to merge this data set with the Google Trends data. However, we first have to clean `NAME` so that it has the same structure as `location` in the search interest by city data. Add a new variable `location` to the ACS data that only includes city names.

```{r}
# Cleaning NAME in ACS data by adding location variable to ACS
acs_il$location <-  gsub(", .*", "",acs_il$NAME)
acs_il$location <- gsub("(city|village|CDP)", "", acs_il$location)
acs_il$location <- trimws(acs_il$location, "right")
head(acs_il)
```

Answer the following questions with the "crime" and "loans" Google trends data and the ACS data.

-   First, check how many cities don't appear in both data sets, i.e. cannot be matched. Then, create a new data set by joining the Google Trends and the ACS data. Keep only cities that appear in both data sets.

```{r}
# Are any of the locations in our search data also in our ACS data?
any(res_city$location %in% acs_il$location)

# Printing how many cities don't appear in both data sets
summary(res_city$location %in% acs_il$location)
summary(acs_il$location %in% res_city$location)

# Doing an inner join, only keeping variables common to both datasets
res_city_acs <- inner_join(res_city, acs_il, by = join_by("location" == "location"))

# Doing an inner join, only keeping variables common to both datasets
res_city_acs <- inner_join(res_city, acs_il, by = join_by("location" == "location"))
nrow(res_city)
nrow(acs_il)
nrow(res_city_acs)
```

-   Compute the mean of the search popularity for both keywords for cities that have an above average median household income and for those that have an below average median household income. When building your pipe, start with creating the grouping variable and then proceed with the remaining tasks. What conclusions might you draw from this?

```{r}
popsearchmean <- res_city_acs%>% 
  mutate(high_hh_income = ifelse(hh_income > mean(hh_income), "Above", "Below")) %>%
  group_by(high_hh_income) %>%
  summarize(mean_pop_crime = mean(crime),
            mean_pop_loans = mean(loans))

knitr::kable(popsearchmean, caption = "Popularity of Crime and Loans Searches Across Low and High-income Illinois Cities")
    ```

-   Is there a relationship between the median household income and the search popularity of the Google trends terms? Describe the relationship and use a scatterplot with `qplot()`.

```{r}
res_city_acs %>%
qplot(x = hh_income, y = crime, data = ., 
      geom = "auto")

res_city_acs %>%
  qplot(x = hh_income, y = loans, data = ., 
            geom = "auto")
ggplot(res_city_acs, aes(crime, loans, colour = hh_income)) + 
  geom_point()
```

Repeat the above steps using the covid data and the ACS data.

-   First, check how many cities don't appear in both data sets, i.e. cannot be matched. Then, create a new data set by joining the Google Trends and the ACS data. Keep only cities that appear in both data sets.

```{r}
# Are any of the locations in our search data also in our ACS data?
any(res_covid_city$location %in% acs_il$location)

# Printing how many cities don't appear in both data sets
summary(res_covid_city$location %in% acs_il$location)
summary(acs_il$location %in% res_covid_city$location)

# Doing an inner join, only keeping variables common to both datasets
res_covid_city_acs <- inner_join(res_covid_city, acs_il, by = join_by("location" == "location"))
```

-   Compute the mean of the search popularity for both keywords for cities that have an above average median household income and for those that have an below average median household income. When building your pipe, start with creating the grouping variable and then proceed with the remaining tasks. What conclusions might you draw from this?

```{r}
# removing NA values in the household income variable
res_covid_city_acs <- res_covid_city_acs %>%
  drop_na(hh_income)

popsearchmean_covid <- res_covid_city_acs%>% 
  mutate(high_hh_income = ifelse(hh_income > mean(hh_income), "Above", "Below")) %>%
  group_by(high_hh_income) %>%
  summarize(mean_pop_covid = mean(covid),
            mean_pop_trump = mean(trump))

knitr::kable(popsearchmean_covid, caption = "Popularity of COVID and Trump Searches Across Low and High-income Illinois Cities")
    ```

-   Is there a relationship between the median household income and the search popularity of the Google trends terms? Describe the relationship and use a scatterplot with `qplot()`.

```{r}
# Running correlations of each
cor(res_covid_city_acs$hh_income,res_covid_city_acs$covid)
cor(res_covid_city_acs$hh_income,res_covid_city_acs$trump)

# Doing qolots of each
res_covid_city_acs %>%
  qplot(x = hh_income, y = covid, data = ., 
        geom = "auto")
res_covid_city_acs %>%
  qplot(x = hh_income, y = trump, data = ., 
        geom = "auto")

# Doing a regular scatterplot in base R
plot(res_covid_city_acs$hh_income,res_covid_city_acs$covid)
plot(res_covid_city_acs$hh_income,res_covid_city_acs$trump)

# Using ggplot
ggplot(res_covid_city_acs, aes(covid, trump, colour = hh_income)) + 
geom_point()
```

